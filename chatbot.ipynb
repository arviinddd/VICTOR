{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b7a80-b159-4db0-9af4-f6ccdbf177a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch stable-baselines3 langchain spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbb9ff59-80b7-4507-bab1-c40a2484abf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class ChatEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(ChatEnvironment, self).__init__()\n",
    "        self.action_space = spaces.Discrete(3)  # Number of actions\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.state = np.array([0.0], dtype=np.float32)  # Initial state\n",
    "        self.done = False\n",
    "        return self.state, {}  # Return observation and additional info\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 1 if action == 0 else -1  # Simplified reward logic\n",
    "        self.state = np.array([0.0], dtype=np.float32)  # Update state\n",
    "        self.done = True  # Simplified, ends after one step\n",
    "        return self.state, reward, self.done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "env = ChatEnvironment()  # Create the Gymnasium environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08cff111-4f07-4057-98c1-bc6326a684f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "def encode_input(text):\n",
    "    return tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "def get_intent(text):\n",
    "    encoded_input = encode_input(text)\n",
    "    output = model(**encoded_input)\n",
    "    return torch.argmax(output.logits, dim=1).item()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class CustomLangChain:\n",
    "    def __init__(self):\n",
    "        self.intent_responses = {\n",
    "            0: \"The tuition fees are...\",\n",
    "            1: \"Here are the steps to apply...\",\n",
    "            2: \"The application deadlines are...\"\n",
    "        }\n",
    "        self.generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "    def generate_response(self, intent):\n",
    "        response_text = self.intent_responses.get(intent, \"I'm sorry, I don't understand.\")\n",
    "        generated_response = self.generator(response_text, max_length=50)\n",
    "        return generated_response[0]['generated_text']\n",
    "\n",
    "dialogue_manager = CustomLangChain()\n",
    "\n",
    "def respond_to_user(input_text):\n",
    "    intent = get_intent(input_text)\n",
    "    doc = nlp(input_text)\n",
    "    response = dialogue_manager.generate_response(intent)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb2f9bf-e1fd-46f7-ab71-33bf70bd7a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0, exploration_decay=0.995):\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_decay = exploration_decay\n",
    "        self.q_table = defaultdict(lambda: np.zeros(action_space.n))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.exploration_rate:\n",
    "            return self.action_space.sample()  # Explore action space\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])  # Exploit learned values\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][best_next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "\n",
    "agent = QLearningAgent(env.action_space)\n",
    "\n",
    "def train_agent(episodes=10000):\n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(tuple(state))\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.learn(tuple(state), action, reward, tuple(next_state))\n",
    "            state = next_state\n",
    "    agent.q_table = dict(agent.q_table)  # Convert defaultdict to dict for saving\n",
    "\n",
    "def save_agent(filepath=\"chatbot_model.npy\"):\n",
    "    np.save(filepath, agent.q_table)\n",
    "\n",
    "def load_agent(filepath=\"chatbot_model.npy\"):\n",
    "    q_table = np.load(filepath, allow_pickle=True).item()\n",
    "    agent.q_table = defaultdict(lambda: np.zeros(env.action_space.n), q_table)\n",
    "\n",
    "train_agent()\n",
    "save_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7069594-84db-46d8-8392-c149cec177bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The application deadlines are... The deadline is August 18, 2017 and so must be fulfilled before it takes place until after the year ends.\"\n",
      "Bot: The application deadlines are...\n",
      "\n",
      "July 31st\n",
      "\n",
      "August 02nd\n",
      "\n",
      "September 18th\n",
      "\n",
      "October 20th\n",
      "\n",
      "January 14th\n",
      "\n",
      "February 15th\n",
      "\n",
      "March 17th\n",
      "\n",
      "April 16th (and earlier)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot_conversation():\n",
    "    load_agent()\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.choose_action(tuple(state))\n",
    "        state, reward, done, _ = env.step(action)\n",
    "    return \"Chat session ended\"  # Simplified, replace with actual rendering logic\n",
    "\n",
    "def handle_chat_session(user_input):\n",
    "    response = respond_to_user(user_input)\n",
    "    print(f\"Bot: {response}\")\n",
    "    return chatbot_conversation()\n",
    "\n",
    "# Example usage\n",
    "user_input = \"How much is tuition?\"\n",
    "handle_chat_session(user_input)\n",
    "\n",
    "user_input = \"When are the deadlines?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "967ff2a7-c028-4790-8b42-77520d79fe06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The application deadlines are... 12/03/2017 11:57:10 AM 11:57:11\n",
      "\n",
      "11:57:10\n",
      "\n",
      "11:57:12\n",
      "\n",
      "11:57:12\n",
      "\n",
      "11:57:12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"Can i know about the deadlines?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1610f38d-b857-46d2-b666-59895b63c092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The application deadlines are... January 12th, 2014 through December 30th, 2014.\n",
      "\n",
      "\n",
      "If the applicant is a candidate for a Bachelor's degree at a university, or a master's degree from a college, you could be eligible for an application\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input =\"Can you give me the full application process\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf024f5-deca-4d2a-88d3-3e5aa15b9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a67721-c834-471d-ae3c-0dfc755613a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class ChatEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(ChatEnvironment, self).__init__()\n",
    "        self.action_space = spaces.Discrete(3)  # Number of actions\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.state = np.array([0.0], dtype=np.float32)  # Initial state\n",
    "        self.done = False\n",
    "        return self.state, {}  # Return observation and additional info\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 1 if action == 0 else -1  # Simplified reward logic\n",
    "        self.state = np.array([0.0], dtype=np.float32)  # Update state\n",
    "        self.done = True  # Simplified, ends after one step\n",
    "        return self.state, reward, self.done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "env = ChatEnvironment()  # Create the Gymnasium environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af016d00-3ffd-49ef-a883-445da44b1e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load Spacy model for text processing\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load JSON data\n",
    "with open(\"files/program_details.json\", 'r') as file:\n",
    "    program_details = json.load(file)\n",
    "with open(\"files/Combined_FAQs.json\", 'r') as file:\n",
    "    faqs = json.load(file)\n",
    "\n",
    "class CustomLangChain:\n",
    "    def __init__(self, programs, faqs):\n",
    "        self.program_details = programs\n",
    "        self.faqs = faqs\n",
    "\n",
    "    def check_faqs(self, query):\n",
    "        query_lower = query.lower()\n",
    "        best_match = None\n",
    "        highest_similarity = 0.0\n",
    "\n",
    "        for category, questions in self.faqs.items():\n",
    "            for question, answer in questions.items():\n",
    "                # Checking if the query words are in the FAQ question\n",
    "                query_tokens = set(query_lower.split())\n",
    "                question_tokens = set(question.lower().split())\n",
    "                common_tokens = query_tokens.intersection(question_tokens)\n",
    "                similarity = float(len(common_tokens)) / len(query_tokens.union(question_tokens))\n",
    "\n",
    "                # Updating to return the answer with the highest similarity\n",
    "                if similarity > highest_similarity and similarity > 0.5:  # Adjust the threshold as needed\n",
    "                    highest_similarity = similarity\n",
    "                    best_match = answer\n",
    "\n",
    "        return best_match\n",
    "\n",
    "\n",
    "    def find_program(self, query):\n",
    "        query_doc = nlp(query.lower())\n",
    "        query_tokens = set([token.lemma_ for token in query_doc if not token.is_stop and not token.is_punct])\n",
    "        best_match = None\n",
    "        max_similarity = 0\n",
    "        for program in self.program_details:\n",
    "            program_name = program['Program Name'].lower()\n",
    "            program_doc = nlp(program_name)\n",
    "            program_tokens = set([token.lemma_ for token in program_doc if not token.is_stop and not token.is_punct])\n",
    "            similarity = len(query_tokens.intersection(program_tokens)) / len(query_tokens.union(program_tokens))\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = program\n",
    "        return best_match\n",
    "\n",
    "    def generate_response(self, intent, input_text):\n",
    "        # Check FAQs first with enhanced matching\n",
    "        faq_response = self.check_faqs(input_text)\n",
    "        if faq_response:\n",
    "            return faq_response\n",
    "\n",
    "        # Proceed with program-specific query if no FAQ response\n",
    "        program = self.find_program(input_text)\n",
    "        if program:\n",
    "            response_templates = {\n",
    "                0: f\"The tuition fees for {program['Program Name']} are not explicitly listed. For more details, please visit {program['URL']}.\",\n",
    "                1: f\"To apply for {program['Program Name']}, please check the detailed application steps at {program['URL']}.\",\n",
    "                2: f\"The application deadline for {program['Program Name']} is {program['Deadline']}.\",\n",
    "                3: f\"{program['Program Name']} is offered by the {program['College Name']}.\",\n",
    "                4: f\"The instruction method for {program['Program Name']} is {program['Instruction Method']}.\",\n",
    "                5: f\"{program['Program Name']} can be pursued on a {program['Full/Part Time Options']} basis.\",\n",
    "                6: f\"{program['Program Name']} requires {program['Credits Required']} credits to complete.\",\n",
    "                7: f\"The estimated time to complete {program['Program Name']} is {program['Time to Degree']}.\",\n",
    "                8: f\"The application fee for {program['Program Name']} is {program['Application Fee']}.\",\n",
    "            }\n",
    "            return response_templates.get(intent, \"I'm sorry, I couldn't find the program you're asking about.\")\n",
    "        return \"I'm sorry, I couldn't find the program you're asking about.\"\n",
    "\n",
    "\n",
    "\n",
    "def get_intent(input_text):\n",
    "    lower_text = input_text.lower()\n",
    "    if \"fee\" in lower_text or \"cost\" in lower_text:\n",
    "        return 0\n",
    "    elif \"apply\" in lower_text:\n",
    "        return 1\n",
    "    elif \"deadline\" in lower_text:\n",
    "        return 2\n",
    "    elif \"college\" in lower_text:\n",
    "        return 3\n",
    "    elif \"method\" in lower_text:\n",
    "        return 4\n",
    "    elif \"time\" in lower_text:\n",
    "        return 5\n",
    "    elif \"credit\" in lower_text:\n",
    "        return 6\n",
    "    elif \"degree time\" in lower_text:\n",
    "        return 7\n",
    "    elif \"application fee\" in lower_text:\n",
    "        return 8\n",
    "    return -1  # No intent recognized\n",
    "\n",
    "# Initialize dialogue manager\n",
    "dialogue_manager = CustomLangChain(program_details, faqs)\n",
    "\n",
    "def respond_to_user(input_text):\n",
    "    intent = get_intent(input_text)  # Placeholder for actual intent determination logic\n",
    "    response = dialogue_manager.generate_response(intent, input_text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f48e57-d4bc-4fb4-81f1-64d9ba8a566a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0, exploration_decay=0.995):\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_decay = exploration_decay\n",
    "        self.q_table = defaultdict(lambda: np.zeros(action_space.n))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.exploration_rate:\n",
    "            return self.action_space.sample()  # Explore action space\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])  # Exploit learned values\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][best_next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "\n",
    "agent = QLearningAgent(env.action_space)\n",
    "\n",
    "def train_agent(episodes=10000):\n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(tuple(state))\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.learn(tuple(state), action, reward, tuple(next_state))\n",
    "            state = next_state\n",
    "    agent.q_table = dict(agent.q_table)  # Convert defaultdict to dict for saving\n",
    "\n",
    "def save_agent(filepath=\"chatbot_model.npy\"):\n",
    "    np.save(filepath, agent.q_table)\n",
    "\n",
    "def load_agent(filepath=\"chatbot_model.npy\"):\n",
    "    q_table = np.load(filepath, allow_pickle=True).item()\n",
    "    agent.q_table = defaultdict(lambda: np.zeros(env.action_space.n), q_table)\n",
    "\n",
    "train_agent()\n",
    "save_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877a6cc5-c98a-4bb2-9db5-7807258008cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chatbot_conversation():\n",
    "    load_agent()\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.choose_action(tuple(state))\n",
    "        state, reward, done, _ = env.step(action)\n",
    "    return \"Chat session ended\"  # Simplified, replace with actual rendering logic\n",
    "\n",
    "def handle_chat_session(user_input):\n",
    "    response = respond_to_user(user_input)\n",
    "    print(f\"Bot: {response}\")\n",
    "    return chatbot_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e034b0-37bf-48ab-93b6-83fcdcdc1d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The application deadline for Data Sciences and Applications MPS is 07/27/2024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"When are the deadlines for data science?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bd869a50-6ae8-496e-8164-10e074dd9f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: To apply for Biochemistry PhD, please check the detailed application steps at https://www.buffalo.edu/grad/programs/biochemistry-phd.html.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"How can I apply for Biochemistry PhD?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15f3026c-083a-441f-b7ab-831d507d75b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: To apply for Biochemistry MA, please check the detailed application steps at https://www.buffalo.edu/grad/programs/biochemistry-ma.html.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"How can I apply for Biochemistry?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de1d53ca-220c-4ff5-a6af-37c299746aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The application deadline for Biochemistry MA is 12/08/2024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"When are the deadlines for Biochemistry?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac42e2f8-40b7-44ed-81ef-3fe4c3427fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Yes! International students are eligible to apply for the 24-month OPT STEM extension.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chat session ended'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"Is data Science a stem program?\"\n",
    "handle_chat_session(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24ebbfbe-9f57-4183-829f-9a8e68e191e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# app.py\n",
    "# app.py\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all domains\n",
    "\n",
    "# Define ChatEnvironment\n",
    "class ChatEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(ChatEnvironment, self).__init__()\n",
    "        self.action_space = spaces.Discrete(3)  # Number of actions\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.state = np.array([0.0], dtype=np.float32)  # Initial state\n",
    "        self.done = False\n",
    "        return self.state, {}  # Return observation and additional info\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 1 if action == 0 else -1  # Simplified reward logic\n",
    "        self.state = np.array([0.0], dtype=np.float32)  # Update state\n",
    "        self.done = True  # Simplified, ends after one step\n",
    "        return self.state, reward, self.done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "env = ChatEnvironment()  # Create the Gymnasium environment\n",
    "\n",
    "# Load Spacy model for text processing\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load JSON data\n",
    "with open(\"files/program_details.json\", 'r') as file:\n",
    "    program_details = json.load(file)\n",
    "with open(\"files/Combined_FAQs.json\", 'r') as file:\n",
    "    faqs = json.load(file)\n",
    "\n",
    "# Define CustomLangChain\n",
    "class CustomLangChain:\n",
    "    def __init__(self, programs, faqs):\n",
    "        self.program_details = programs\n",
    "        self.faqs = faqs\n",
    "\n",
    "    def check_faqs(self, query):\n",
    "        query_lower = query.lower()\n",
    "        best_match = None\n",
    "        highest_similarity = 0.0\n",
    "\n",
    "        for category, questions in self.faqs.items():\n",
    "            for question, answer in questions.items():\n",
    "                query_tokens = set(query_lower.split())\n",
    "                question_tokens = set(question.lower().split())\n",
    "                common_tokens = query_tokens.intersection(question_tokens)\n",
    "                similarity = float(len(common_tokens)) / len(query_tokens.union(question_tokens))\n",
    "\n",
    "                if similarity > highest_similarity and similarity > 0.5:  # Adjust the threshold as needed\n",
    "                    highest_similarity = similarity\n",
    "                    best_match = answer\n",
    "\n",
    "        return best_match\n",
    "\n",
    "    def find_program(self, query):\n",
    "        query_doc = nlp(query.lower())\n",
    "        query_tokens = set([token.lemma_ for token in query_doc if not token.is_stop and not token.is_punct])\n",
    "        best_match = None\n",
    "        max_similarity = 0\n",
    "        for program in self.program_details:\n",
    "            program_name = program['Program Name'].lower()\n",
    "            program_doc = nlp(program_name)\n",
    "            program_tokens = set([token.lemma_ for token in program_doc if not token.is_stop and not token.is_punct])\n",
    "            similarity = len(query_tokens.intersection(program_tokens)) / len(query_tokens.union(program_tokens))\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = program\n",
    "        return best_match\n",
    "\n",
    "    def generate_response(self, intent, input_text):\n",
    "        faq_response = self.check_faqs(input_text)\n",
    "        if faq_response:\n",
    "            return faq_response\n",
    "\n",
    "        program = self.find_program(input_text)\n",
    "        if program:\n",
    "            response_templates = {\n",
    "                0: f\"The tuition fees for {program['Program Name']} are not explicitly listed. For more details, please visit {program['URL']}.\",\n",
    "                1: f\"To apply for {program['Program Name']}, please check the detailed application steps at {program['URL']}.\",\n",
    "                2: f\"The application deadline for {program['Program Name']} is {program['Deadline']}.\",\n",
    "                3: f\"{program['Program Name']} is offered by the {program['College Name']}.\",\n",
    "                4: f\"The instruction method for {program['Program Name']} is {program['Instruction Method']}.\",\n",
    "                5: f\"{program['Program Name']} can be pursued on a {program['Full/Part Time Options']} basis.\",\n",
    "                6: f\"{program['Program Name']} requires {program['Credits Required']} credits to complete.\",\n",
    "                7: f\"The estimated time to complete {program['Program Name']} is {program['Time to Degree']}.\",\n",
    "                8: f\"The application fee for {program['Program Name']} is {program['Application Fee']}.\",\n",
    "            }\n",
    "            return response_templates.get(intent, \"I'm sorry, I couldn't find the program you're asking about.\")\n",
    "        return \"I'm sorry, I couldn't find the program you're asking about.\"\n",
    "\n",
    "# Define intent recognition\n",
    "def get_intent(input_text):\n",
    "    lower_text = input_text.lower()\n",
    "    if \"fee\" in lower_text or \"cost\" in lower_text:\n",
    "        return 0\n",
    "    elif \"apply\" in lower_text:\n",
    "        return 1\n",
    "    elif \"deadline\" in lower_text:\n",
    "        return 2\n",
    "    elif \"college\" in lower_text:\n",
    "        return 3\n",
    "    elif \"method\" in lower_text:\n",
    "        return 4\n",
    "    elif \"time\" in lower_text:\n",
    "        return 5\n",
    "    elif \"credit\" in lower_text:\n",
    "        return 6\n",
    "    elif \"degree time\" in lower_text:\n",
    "        return 7\n",
    "    elif \"application fee\" in lower_text:\n",
    "        return 8\n",
    "    return -1  # No intent recognized\n",
    "\n",
    "# Initialize dialogue manager\n",
    "dialogue_manager = CustomLangChain(program_details, faqs)\n",
    "\n",
    "def respond_to_user(input_text):\n",
    "    intent = get_intent(input_text)\n",
    "    response = dialogue_manager.generate_response(intent, input_text)\n",
    "    return response\n",
    "\n",
    "# Define Q-learning agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0, exploration_decay=0.995):\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_decay = exploration_decay\n",
    "        self.q_table = defaultdict(lambda: np.zeros(action_space.n))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.exploration_rate:\n",
    "            return self.action_space.sample()  # Explore action space\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])  # Exploit learned values\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][best_next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "\n",
    "agent = QLearningAgent(env.action_space)\n",
    "\n",
    "def train_agent(episodes=10000):\n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(tuple(state))\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.learn(tuple(state), action, reward, tuple(next_state))\n",
    "            state = next_state\n",
    "    agent.q_table = dict(agent.q_table)  # Convert defaultdict to dict for saving\n",
    "\n",
    "def save_agent(filepath=\"chatbot_model.npy\"):\n",
    "    np.save(filepath, agent.q_table)\n",
    "\n",
    "def load_agent(filepath=\"chatbot_model.npy\"):\n",
    "    q_table = np.load(filepath, allow_pickle=True).item()\n",
    "    agent.q_table = defaultdict(lambda: np.zeros(env.action_space.n), q_table)\n",
    "\n",
    "train_agent()\n",
    "save_agent()\n",
    "\n",
    "def chatbot_conversation():\n",
    "    load_agent()\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.choose_action(tuple(state))\n",
    "        state, reward, done, _ = env.step(action)\n",
    "    return \"Chat session ended\"  # Simplified, replace with actual rendering logic\n",
    "\n",
    "def handle_chat_session(user_input):\n",
    "    response = respond_to_user(user_input)\n",
    "    print(f\"Bot: {response}\")\n",
    "    return chatbot_conversation()\n",
    "\n",
    "@app.route('/send', methods=['POST'])\n",
    "def handle_message():\n",
    "    user_input = request.json['message']\n",
    "    response = respond_to_user(user_input)\n",
    "    return jsonify({'reply': response})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5001)  # Run the server on port 5001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66a54a-bfb1-4103-8434-c8de3522638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with watchdog (fsevents)\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 759-075-018\n",
      "127.0.0.1 - - [26/Jun/2024 18:47:36] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 18:47:59] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:14:33] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:14:48] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:15:32] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:16:02] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:16:03] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:16:32] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:16:54] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:17:38] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:18:00] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:18:20] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:18:33] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:18:57] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:19:07] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:19:23] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:19:30] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:20:41] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:20:58] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:21:10] \"POST /send HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jun/2024 23:21:17] \"POST /send HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e68fb-b794-4621-9230-7a3d19c50f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Rasa)",
   "language": "python",
   "name": "python3.8-rasa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
